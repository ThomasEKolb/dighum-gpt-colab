{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThomasEKolb/dighum-gpt-colab/blob/main/dighum_gpt_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Digital Humanism Summer School 2023: Hands-on Session ChatGPT\n"
      ],
      "metadata": {
        "id": "avHDg9TwGTGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 1"
      ],
      "metadata": {
        "id": "sj-cBxBuBCJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install All Required Packages"
      ],
      "metadata": {
        "id": "vo1qEQPRGpeZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlSXvBACjy-T"
      },
      "outputs": [],
      "source": [
        "%pip install langchain\n",
        "%pip install pypdf\n",
        "%pip install openai\n",
        "%pip install tiktoken\n",
        "%pip install chromadb\n",
        "%pip install pdfminer\n",
        "%pip install wget\n",
        "%pip install pdfminer.six\n",
        "%pip install unstructured"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Connect Your Personal Google Drive (optional)\n",
        "\n",
        "You can attach your personal google drive with the following code:"
      ],
      "metadata": {
        "id": "AYVvDfL-Gys_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "fM2XldwLGPKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Fill In Your OpenAI API Key"
      ],
      "metadata": {
        "id": "a5v--YASG-KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "0kllS2NoHG9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Now We Initialize the Openai Connection"
      ],
      "metadata": {
        "id": "yEacHWL2Su4s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Hvt9VTXYjy-V",
        "outputId": "cb25fa1d-a698-4d5d-e9c4-3c4b06d6852b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "llm = OpenAI()\n",
        "chat_model = ChatOpenAI()\n",
        "chat_model.predict(\"hi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Parse the Book PDF into Text"
      ],
      "metadata": {
        "id": "YGJ-_eTFS5G6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jbTkyRYjy-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c21200-36a6-43df-db79-031e58615af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "978-3-030-86144-5.pdf\n"
          ]
        }
      ],
      "source": [
        "# from langchain.document_loaders import PyPDFLoader\n",
        "# from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.document_loaders import PDFMinerLoader\n",
        "import wget\n",
        "\n",
        "url_book = \"https://owncloud.tuwien.ac.at/index.php/s/FW7Y2GNUOaUtrhf/download\" # book as pdf\n",
        "book_filename = wget.download(url_book)\n",
        "print(book_filename)\n",
        "\n",
        "# loader = PyPDFLoader(\"978-3-030-86144-5.pdf\")\n",
        "# loader = UnstructuredPDFLoader(\"978-3-030-86144-5.pdf\")\n",
        "loader = PDFMinerLoader(\"./978-3-030-86144-5.pdf\")\n",
        "book = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'You have {len(book)} books(s) in your data')\n",
        "print (f'There are {len(book[0].page_content)} characters in your book')"
      ],
      "metadata": {
        "id": "YeSysMgCL3XH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c5b146-4404-44dc-97f1-695b5dfa2885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 1 books(s) in your data\n",
            "There are 852331 characters in your book\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Split the Text into Smaller Chunks"
      ],
      "metadata": {
        "id": "w2p1TaNRTHCo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlPVH_I9rwI7"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(book)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'The book is now divided into {len(texts)} parts.')"
      ],
      "metadata": {
        "id": "xtBgp-LsMf8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93a5f94-8dab-4161-dd5e-194194686095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The book is now divided into 1182 parts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Create Embeddings Based on the Created Chunks"
      ],
      "metadata": {
        "id": "I0XRYjmnTTeY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5r7umlrsOFw"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings(chunk_size=1,deployment='text-embedding-ada-002')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfbM5QqCjy-V"
      },
      "outputs": [],
      "source": [
        "#from langchain.vectorstores import Chroma\n",
        "#persist_directory = './db' # or store it directly into your personal drive: '/content/drive/MyDrive/db'\n",
        "#croma_db = Chroma.from_documents(documents=texts, embedding=embedding, persist_directory=persist_directory)\n",
        "#croma_db.persist() # store embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "persist_directory = './db'\n",
        "\n",
        "# download the embeddings (to save some time and cost)\n",
        "url_embeddings = \"https://owncloud.tuwien.ac.at/index.php/s/xwFts1mQo3VXiCg/download\" # embeddings of the book\n",
        "embeddings_filename = wget.download(url_embeddings)\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('./'+embeddings_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')\n",
        "\n",
        "print(embeddings_filename)\n",
        "\n",
        "# load data from vector store\n",
        "croma_db = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
      ],
      "metadata": {
        "id": "idyRY6VbzloT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f09d758-8128-49cf-e7d2-b5ae7a465538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "db-20230831T161118Z-001.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Make Use of the Langchain Framework to Provide a Text Based Search Interface"
      ],
      "metadata": {
        "id": "33prIDx-Td_N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnbTqKskst5Q"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=croma_db.as_retriever(),\n",
        "                                 return_source_documents=False\n",
        "                                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill in your questions about the book"
      ],
      "metadata": {
        "id": "ebd6o6pRTp8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Explain digital humanism to a child of 6 years.\" # @param {type:\"string\"}\n",
        "qa.run(query)"
      ],
      "metadata": {
        "id": "b1mnzzijEizR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0eb25a88-f6c3-4b63-cc25-b1ab4a4a5b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Digital humanism is a way of using technology to make the world better for people and animals and to protect the environment for future generations. It encourages people to make their own decisions and be in control of the technology, rather than letting machines make decisions for them.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 2"
      ],
      "metadata": {
        "id": "968hvlCdAVPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Incorporate various heterogeneous data sources"
      ],
      "metadata": {
        "id": "c7q0YSs9L5kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredHTMLLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "import wget\n",
        "\n",
        "url_program = \"https://owncloud.tuwien.ac.at/index.php/s/hX8wLPxv6rXAdgM/download\" #https://caiml.dbai.tuwien.ac.at/dighum/summerschool2023/program/\n",
        "url_manifesto = \"https://owncloud.tuwien.ac.at/index.php/s/h2457gToxxlgnpN/download\" #https://caiml.dbai.tuwien.ac.at/dighum/dighum-manifesto/\n",
        "program_filename = wget.download(url_program)\n",
        "manifesto_filename = wget.download(url_manifesto)\n",
        "print(program_filename,manifesto_filename)\n",
        "\n",
        "html_loader = UnstructuredHTMLLoader(program_filename)\n",
        "txt_loader = TextLoader(manifesto_filename)\n",
        "program = html_loader.load()\n",
        "manifesto = txt_loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzxsbNsBL3D8",
        "outputId": "304939cb-81a6-4b1a-89d5-7cefaafb7a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dighum_program (1).html DigHum_Manifesto (1).txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'There are {len(program[0].page_content)} characters on the webpage')\n",
        "print (f'There are {len(manifesto[0].page_content)} characters in the manifesto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-aprbSpOfxp",
        "outputId": "a061e39c-0f6f-4b23-d6ac-4d26f74b8876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 10955 characters on the webpage\n",
            "There are 7871 characters in the manifesto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter2 = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "program_texts = text_splitter2.split_documents(program)\n",
        "manifesto_texts = text_splitter2.split_documents(manifesto)\n",
        "combined_texts = program_texts + manifesto_texts\n",
        "\n",
        "print (f'The texts are now divided into {len(combined_texts)} parts.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbd39o-5Rs-h",
        "outputId": "df24dc39-10f5-4923-a97e-2d964a3c469a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The texts are now divided into 28 parts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsVjcBNDSMHr"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "persist_directory2 = './db2' # or store it directly into your personal drive: '/content/drive/MyDrive/db'\n",
        "croma_db2 = Chroma.from_documents(documents=combined_texts, embedding=embedding, persist_directory=persist_directory2)\n",
        "croma_db2.persist() # store embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa2 = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=croma_db2.as_retriever(),\n",
        "                                 return_source_documents=False\n",
        "                                 )"
      ],
      "metadata": {
        "id": "G5Grg41KdkbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Show me the schedule of the summer school for Monday morning?\" # @param {type:\"string\"}\n",
        "qa2.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5B5FdtRFdw5r",
        "outputId": "9004dfa5-6558-4dbd-b418-b492cb8c44cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Monday, September 4, 2023\\n8:30 - 9:00 Registration\\nMorning (9:00-12:30)\\n9:00 - 9:30 Opening and Welcome\\n9:30 - 9:45 Welcome Address by Dean Gerti Kappel\\n9:45 - 10:00 Welcome Address by\\xa0Enrico Nardelli\\xa0(ACM Europe)\\n10:00 - 11:00\\xa0Hannes Werthner: Introduction to Digital Humanism\\n11:30 - 12:30\\xa0George Metakides: Digital Enlightenment'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who are the authors of the DigHum Manifesto?\" # @param {type:\"string\"}\n",
        "qa2.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "cellView": "form",
        "id": "7Vzu6sKbeHlL",
        "outputId": "ca6ba7ab-d221-488b-8a6a-8ca30d0eb7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The authors of the DigHum Manifesto are scientists and practitioners from across fields and topics, brought together by concerns and hopes for the future.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prompt engineering"
      ],
      "metadata": {
        "id": "lbeFa_dFgWfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "summary_template = PromptTemplate.from_template(\"Please give me a concise of the book chapter {chapter} by {author}.\")"
      ],
      "metadata": {
        "id": "VlxLhY6EgVsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(summary_template.format(chapter=\"Are We Losing Control?\",author=\"Edward A. Lee\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1ACL1AdVnM3I",
        "outputId": "47d8c154-ef2b-4e0e-a937-87911303ff57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The book chapter Are We Losing Control? by Edward A. Lee suggests that humanity never had full control over technology, but that it is possible to nudge the process in a more humane direction through a more human-centric approach. Intellectuals from all disciplines, technologists with a deeper understanding of the humanities, and policy makers must work together to achieve this goal.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommendation_template = PromptTemplate.from_template(\n",
        "\"I want you to act as a recommender system that recommends book chapters (along with their authors) that are related to the following topic: {topic}\")"
      ],
      "metadata": {
        "id": "tFdQRuyX_ayd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(recommendation_template.format(topic=\"Artificial Intelligence\"))"
      ],
      "metadata": {
        "id": "rLRAOhbUAHvT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "085b3553-9695-43cc-bb85-cf4f16801f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Chapter 3, \"The Attention Economy and the Impact of Artificial Intelligence,\" by Lynda Hardman.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "c09aee4d7efaedb00d5ea6540845ce31404264cd93c0d4744716e98598280221"
    },
    "kernelspec": {
      "display_name": "Python 3.10.12 ('dighum-v1')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}